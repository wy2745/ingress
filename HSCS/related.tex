\section{Related Work}
\label{sec:related_work}

\subsection{Load balancing classification}

\hspace{0pt}
According to R Kaur~{\cite{Kaur2014Load}}, load balancing algorithms can be mainly divided into two types: static load balancing algorithm and dynamic load balancing algorithm. Furthermore, dynamic algorithms have two types,
they are distributed and non-distributed approach. The biggest difference between static and dynamic algorithms is whether they depend on server load or request property. A request can either access a file or require processing data. Some researches have been done to reduce latency to access static files:
S Ayyasamy~{\cite{Ayyasamy2010A}} concentrates on static resource placement in P2P content distribution. According to acccess frequency, static resources are divided into hot and cold resources. Data transmission performance is enhanced by placing hot resources to server with
stronger processing ability and lower access latency. G Park adopts choice algorithm to optimize file replication and data partition policies. Q Huang~{\cite{Huang2014Characterizing}} uses hashing and cache to migrate load imbalance. other researches focus on data-processing requests: Sharma~{\cite{Sharma2011Framework}} performs dynamic load balancing
under the assumption that the resource consumption of request have already been known as job metric, he measures servers by several metrics like ability metric and load metric. With the combination of job metric and server metrics,
he evens load across servers. Chandak~{\cite{Chandak2012Dynamic}} divides servers into three levels: lightly loaded, moderately loaded and heavily loaded accoring to their cpu usage. In his research, moderately loaded is regarded as the stable and final
level, he performs load balancing by dispatching more workload to lightly loaded server and less workload to heavily loaded servers. L Zhang~{\cite{Zhang2010A}} describes processing time of a request with cpu processing time, memory usage and disk access time. For each server,
he maintains a mission list to record requests the server is processing. When a new request arrives, if the processing ability of servers is higher than the requirement sum of the new request and requests in mission list, they are regarded suitable to process the request.
Z Xu~{\cite{Xu2014A}} and ME Gebrehiwot~{\cite{Gebrehiwot2017Energy}} adjust weight of servers in Round-robin and least connection algorithm according to their ability. G Velusamy~{\cite{Velusamy2017Smart}} defines server affinity to adjust load balancing algorithm. The server affinity presents whether a server can handler a specific request type faster than
other server. Loadbalancer collects and analyzes logs from servers all the time to get real-time server affinity, with which it dispatches requests to suitable servers. V Cardellini~{\cite{Cardellini2015Dynamic}} proposes the adaptive TTL algorithm, which adds geographic information and server load to the Round-robin algorithm. The adaptive TTL algorithm
tends to dispatch requests to low-loaded servers that are geographically close to requests senders.Unlike the non-distributed approaches mentioned above, Eludiora~{\cite{Eludiora2010A}} and Menon~{\cite{Menon2013A}} adopt distributed solutions. Eludiora's research regulates jobs/tasks migration to minimize extra bandwidth consumption, and therefore improve RPS.
Menon establishes a broadcast protocol for server, for each low-loaded server, it broadcast its ip to two random servers, if these servers are overload, they transfer new requests to the low-loaded servers.

Unfortunately, there is no effective solution for load balancing of container-based cluster. For container-based cluster like Kubernetes, containers generally own the same geographical position and the same process ability. The key factors that cause load imbalance are the resource consumption of request and dependency between services. So this paper proposes
a load monitor to learn resource consumption and a more thorough load metric for server, which adopt service dependency.
\subsection{Load balancing metrics}

Metrics are needed to evaluate performance of a load balancing algorithm. R Kaur~{\cite{Kaur2014Load}} summarys that throughput is calculated to the ability of algorithm to process as many requests as possible during a fixed period. The performance of algorithm is high if its throughput is high. Response time is the time that are taken to process a request.
With a lower response time, a algorithm acheives better performance. This paper uses RPS to cover throughput and response time, a higher RPS means that requests are led to more suitable servers, thus bringing lowwer response time and higher throughput. For distributed algorithm, migration time costed by migrating request from one server to another is calculated
to evaluate performance. Apart from RPS, this paper proposes faults. If a algorithm failes to balance load, overload servers may failes to process requests, cauing 503 Service Unavailable.  Though virtualization has been studied extensively in recent years, \gpu{} virtualization is still a nascent area of research. Typically, there are four ways to use \gpu{} in a \vm{}: I/O pass-through, device emulation, API remoting, and mediated pass-through.

A naive way to use \gpu{} in virtualized environment would be to directly pass through the device to a specific \vm{}~{\cite{hiremane2007intel, dong2009towards}}. However, the \gpu{} resources are dedicated and cannot be multiplexed.

Device emulation, similar to binary translation in CPU virtualization, is impractical. \gpu{}s, unlike CPUs, whose specifications are not well documented, vary between vendors~{\cite{dowty2009gpu}}. Emulating \gpu{}s from different vendors requires vast engineering work. Notably, following up the new \gpu{} hardware would make it a nightmare to maintain the codebase.

API remoting is widely used in commercial softwares such as VMWare and VirtualBox, and has been studied throughout many years. By using API remoting, graphic commands are forwarded from guest OS to host. VMGL~{\cite{lagar2007vmm}} and Oracle VirtualBox~{\cite{website:vbox}}, both based on Chromium~{\cite{humphreys2002chromium}}, replace the standard OpenGL library in Linux Guests with its own implementation to pass the OpenGL commands to VMM. Nonetheless, forwarding OpenGL commands is not considered a general solution, since Microsoft Windows mainly uses their own DirectX API. Whether forwarding OpenGL or DirectX commands, it would be difficult to emulate the other API.
gVirtuS~{\cite{giunta2010gpgpu}}, VGRIS~{\cite{qi2014vgris}}, GViM~{\cite{gupta2009gvim}}, rCUDA~{\cite{duato2010rcuda}} and vCUDA~{\cite{shi2012vcuda}} use the same manner to forward CUDA and OpenCL commands, solving the problem of virtualizing GPGPU applications.

VMware's products consist of a virtual PCI device, SVGA \RNum{2} card~{\cite{dowty2009gpu}}, and the corresponding driver for different operating systems. The emulated device acts like a real video card which has registers, graphics memory and a FIFO command queue. All accesses to the virtual PCI device inside a VM is handled on the host side, by a user-level process, where the actual work is performed. Moreover, they have designed another graphic API called SVGA3D. The SVGA3D protocol is similar to Direct3D and shares a common abstraction. The purpose of SVGA3D is to eliminate the commands for a specific GPU. Meanwhile, a \gpu{} can also emulate the missing features by SVGA3D protocol, which provides a practical portability for their products.

Recently, two full \gpu{} virtualization solutions have been proposed, i.e., \gvirt{} of Intel~{\cite{tian2014full}} and GPUvm~{\cite{suzuki2014gpuvm}}, respectively. \gvirt{} is the first open source product level full \gpu{} virtualization solution in Intel platforms. \gvirt{} presents a v\gpu{} instance to each VM which allows the native graphics driver to be run in VM. The shadow page table is updated with a coarse-grained model, which could lead to a performance pitfall under some video memory intensive workloads, such as media transcoding.

GPUvm presents a \gpu{} virtualization solution on a NVIDIA card. Both para- and full-virtualization were implemented. However, full-virtualization exhibits a considerable overhead for MMIO handling. The performance of optimized para-virtualization is two to three times slower than native. Since NVIDIA has individual graphics memory on the PCI card, while the Intel \gpu{} uses part of main memory as its graphics memory, the way of handling memory virtualization is different. GPUvm cannot handle page faults caused by NVIDIA \gpu{}s~{\cite{gottschlag2013logv}}. As a result, they must scan the entire page table when translation lookaside buffer (TLB) flushes. As \name{} allocates graphics memory within the main memory, VMM can write-protect the page tables to track the page table modifications. This fine-grained page table update mechanism mitigates the overhead incurred by the Massive Update Issue.

NVIDIA GRID~{\cite{website:nvidiagrid}} is a proprietary virtualization solution from NVIDIA for Kepler architecture. However, there are no technical details about their products available to the public.

\subsection{Memory Virtualization}

One important aspect in \gpu{} virtualization is memory virtualization, which has been thoroughly researched. The software method employs a shadow page table to reduce the overhead of translating a VM's virtual memory address. This approach could incur severe overhead under some circumstances. Agesen~\emph{et~al.}~{\cite{agesen2010evolution}} listed three situations where the shadow page table cannot handle well: the hidden page fault, address space switching, and the tracing page table entries. They also pointed out some optimization techniques, such as the trace mechanism and eager validating. Unfortunately, it is hard to trade off these mutually exclusive techniques. Therefore, AMD and Intel have added the hardware support for memory virtualization. All three overheads previously listed before can be eliminated, but it is not the silver bullet, a TLB miss punishment is higher in the hardware solution.
\hspace{0pt}
In the classical VMM implementations, VMM employs a trace technique to prevent its shadow PTEs from becoming inconsistent with guest PTEs, i.e. updating shadow page table strictly after the guest page table is modified. Typically, VM trace uses write-protection mechanism, which can be the source of overhead. This technique is similar to the current \gvirt{}'s strict page table shadowing mechanism, which frequently traps and emulates the page faults of the shadow page table, and it causes overhead. \name{} removes the write-protection from shadow page table to eliminate the overhead caused by excessive trap-and-emulation, taking advantage of the \gpu{} programming model~{\cite{adams2006comparison}}.
