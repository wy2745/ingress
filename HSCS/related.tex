\section{Related Work}
\label{sec:related_work}

\subsection{\gpu{} Benchmarks}

\hspace{0pt}
Since \gpu{}s are used for acceleration of general purpose computing, some benchmarks have been implemented for evaluating their performance. Rodinia~{\cite{che2009rodinia}} is a benchmark suite for heterogeneous computing. It aids architects in the study of emerging platforms such as \gpu{}s. Rodinia includes applications and kernels that target multi-core CPU and GPU platforms. And Parboil~{\cite{stratton2012parboil}} is a set of throughput computing applications useful for studying the performance of throughput computing architecture and compilers.â€  It collects benchmarks from throughput computing application researchers in many different scientific and commercial fields including image processing, bio-molecular simulation, fluid dynamics, and astronomy.

Unfortunately, the benchmarks above are not available for Intel's GPU now. Meanwhile, GPU's media performance has become a big concern for service providers. However, there is no benchmark specifically for this kind of workload. So, this paper proposes GMedia, a media transcoding benchmark based on Intel's MSDK.

\subsection{\gpu{} Virtualization}

Though virtualization has been studied extensively in recent years, \gpu{} virtualization is still a nascent area of research. Typically, there are four ways to use \gpu{} in a \vm{}: I/O pass-through, device emulation, API remoting, and mediated pass-through.

A naive way to use \gpu{} in virtualized environment would be to directly pass through the device to a specific \vm{}~{\cite{hiremane2007intel, dong2009towards}}. However, the \gpu{} resources are dedicated and cannot be multiplexed.

Device emulation, similar to binary translation in CPU virtualization, is impractical. \gpu{}s, unlike CPUs, whose specifications are not well documented, vary between vendors~{\cite{dowty2009gpu}}. Emulating \gpu{}s from different vendors requires vast engineering work. Notably, following up the new \gpu{} hardware would make it a nightmare to maintain the codebase.

API remoting is widely used in commercial softwares such as VMWare and VirtualBox, and has been studied throughout many years. By using API remoting, graphic commands are forwarded from guest OS to host. VMGL~{\cite{lagar2007vmm}} and Oracle VirtualBox~{\cite{website:vbox}}, both based on Chromium~{\cite{humphreys2002chromium}}, replace the standard OpenGL library in Linux Guests with its own implementation to pass the OpenGL commands to VMM. Nonetheless, forwarding OpenGL commands is not considered a general solution, since Microsoft Windows mainly uses their own DirectX API. Whether forwarding OpenGL or DirectX commands, it would be difficult to emulate the other API.
gVirtuS~{\cite{giunta2010gpgpu}}, VGRIS~{\cite{qi2014vgris}}, GViM~{\cite{gupta2009gvim}}, rCUDA~{\cite{duato2010rcuda}} and vCUDA~{\cite{shi2012vcuda}} use the same manner to forward CUDA and OpenCL commands, solving the problem of virtualizing GPGPU applications.

VMware's products consist of a virtual PCI device, SVGA \RNum{2} card~{\cite{dowty2009gpu}}, and the corresponding driver for different operating systems. The emulated device acts like a real video card which has registers, graphics memory and a FIFO command queue. All accesses to the virtual PCI device inside a VM is handled on the host side, by a user-level process, where the actual work is performed. Moreover, they have designed another graphic API called SVGA3D. The SVGA3D protocol is similar to Direct3D and shares a common abstraction. The purpose of SVGA3D is to eliminate the commands for a specific GPU. Meanwhile, a \gpu{} can also emulate the missing features by SVGA3D protocol, which provides a practical portability for their products.

Recently, two full \gpu{} virtualization solutions have been proposed, i.e., \gvirt{} of Intel~{\cite{tian2014full}} and GPUvm~{\cite{suzuki2014gpuvm}}, respectively. \gvirt{} is the first open source product level full \gpu{} virtualization solution in Intel platforms. \gvirt{} presents a v\gpu{} instance to each VM which allows the native graphics driver to be run in VM. The shadow page table is updated with a coarse-grained model, which could lead to a performance pitfall under some video memory intensive workloads, such as media transcoding.

GPUvm presents a \gpu{} virtualization solution on a NVIDIA card. Both para- and full-virtualization were implemented. However, full-virtualization exhibits a considerable overhead for MMIO handling. The performance of optimized para-virtualization is two to three times slower than native. Since NVIDIA has individual graphics memory on the PCI card, while the Intel \gpu{} uses part of main memory as its graphics memory, the way of handling memory virtualization is different. GPUvm cannot handle page faults caused by NVIDIA \gpu{}s~{\cite{gottschlag2013logv}}. As a result, they must scan the entire page table when translation lookaside buffer (TLB) flushes. As \name{} allocates graphics memory within the main memory, VMM can write-protect the page tables to track the page table modifications. This fine-grained page table update mechanism mitigates the overhead incurred by the Massive Update Issue.

NVIDIA GRID~{\cite{website:nvidiagrid}} is a proprietary virtualization solution from NVIDIA for Kepler architecture. However, there are no technical details about their products available to the public.

\subsection{Memory Virtualization}

One important aspect in \gpu{} virtualization is memory virtualization, which has been thoroughly researched. The software method employs a shadow page table to reduce the overhead of translating a VM's virtual memory address. This approach could incur severe overhead under some circumstances. Agesen~\emph{et~al.}~{\cite{agesen2010evolution}} listed three situations where the shadow page table cannot handle well: the hidden page fault, address space switching, and the tracing page table entries. They also pointed out some optimization techniques, such as the trace mechanism and eager validating. Unfortunately, it is hard to trade off these mutually exclusive techniques. Therefore, AMD and Intel have added the hardware support for memory virtualization. All three overheads previously listed before can be eliminated, but it is not the silver bullet, a TLB miss punishment is higher in the hardware solution.
\hspace{0pt}
In the classical VMM implementations, VMM employs a trace technique to prevent its shadow PTEs from becoming inconsistent with guest PTEs, i.e. updating shadow page table strictly after the guest page table is modified. Typically, VM trace uses write-protection mechanism, which can be the source of overhead. This technique is similar to the current \gvirt{}'s strict page table shadowing mechanism, which frequently traps and emulates the page faults of the shadow page table, and it causes overhead. \name{} removes the write-protection from shadow page table to eliminate the overhead caused by excessive trap-and-emulation, taking advantage of the \gpu{} programming model~{\cite{adams2006comparison}}.
