\section{Introduction}
\label{sec:introduction}

The rapid growth of internet introduces a new economy pattern named internet economy, under which almost all activities can be supported by web services through PCs or mobile devices. Aiming to achieve high resource utilization, web applications tend to be deployed into cluster based on a lightweight virtualization called container just like other traditional applications do. Unlike traditional applications which only execute job assigned in advance, web services have to listen on users'  requests and responses as soon as possible. Workload of web services are changing unpredictably because they offer varied businesses, each business consists of operations that may consume CPU, allocate memory or access disk, and it is impossible to know which business will be executed in any time. The unpredictable workload introduces a hug challenge on load-balancing. Unfortunately, the container-based solutions like Kubernetes fail to cope with this challenge, their fair load-balancing solution performs well only when workload are the same, which is contrary to workload of web services, as a result, web services fail to gain high resource utilization, it loses stability and performance conversely.

To address the load balance problem, this paper introduce a dynamic load-balancing solution based on Kubernetes, a popular container cluster management system. The new solution mainly covers two issues: Load collection and load-balancing algorithm.
 To address the load collection issue, we implement a load monitor to evaluate resource consumption of requests and collect load of backend containers. Through collecting and analyzing logs of web services, monitor generates description for different request in requirement of CPU, memory, disk and network. Through listening on status changes of container, monitor generates load description for usage of CPU, memory and network.

For the algorithm part, we introduce request and container models based on description generated by monitor. The generation of models considers not only the load description, but also other details such as the locality, deployment configuration of container and so on. Request dispatching is done through matching request models to container models.

In summary, this paper makes the following contributions:

\begin{itemize}

\item A load monitor for learning resource consumption of requests and listening load changes of containers.

  \item A dynamic load-balancing algorithm which combines resource consumption of request and real-time load of container to dispatch request and finally achieve stability, high performance and high resource utilization for web services.

  \item An evaluation to show the performance of dynamic load-balancing solution.
 % \item A \gpu{}-enabled benchmark for media transcoding performance (GMedia), by invoking functions from Intel MSDK to evaluate and report the  performance on Intel's \gpu{} platforms.


\end{itemize}
The rest of the paper is organized as follows: Section 2 describe background information about performance of web services in container-base cluster. Section 3 presents the design and implementation of dynamic load-balancing solution. Then section 4 evaluate the solution. Section 5 shows the related work, and finally section 6 discuss on the future work.

The rest of the paper is organized as follows: Section~\ref{sec:background} describes some background information 
on \gvirt{} and \gpu{} programming model. Section~\ref{sec:benchmark} presents our benchmark for media transcoding 
and discusses the Massive Update Issue in detail, followed by the design and implementation of \name{} 
 In section~\ref{sec:design_and_impl}. Then, section~\ref{sec:evaluation} evaluates the \name{} and
 section~\ref{sec:related_work} discusses the related work. Finally, section~\ref{sec:conclusion} concludes with
 a brief discussion on future work. 
